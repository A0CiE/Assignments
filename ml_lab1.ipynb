{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml_lab1.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOLOoXDCaK2c6q7mVyHmd01",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/A0CiE/Assignments/blob/master/ml_lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2V0J7VOqYcD"
      },
      "source": [
        "import re\n",
        "from collections import defaultdict\n",
        "import os\n",
        "import tarfile\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "from sklearn import svm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myWOL-YF3meN"
      },
      "source": [
        "import shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rolVLWjV3o21"
      },
      "source": [
        "shutil.rmtree(\"lingspam_public\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihYV_xhIYn3h"
      },
      "source": [
        "TRAIN_FOLDER =['part1','part2','part3','part4','part5','part6','part7','part8','part9']\n",
        "TEST_FOLDER = ['part10']\n",
        "train_dir = []\n",
        "test_dir = []\n",
        "with tarfile.open('lingspam_public.tar.gz', 'r:gz') as tar:\n",
        "  for tarinfo in tar.getmembers():\n",
        "    for folder in TRAIN_FOLDER:\n",
        "      if tarinfo.name.startswith(os.path.join(\"lingspam_public\",\"lemm_stop\",folder,\"\")):\n",
        "        train_dir.append(tarinfo.name)\n",
        "        tar.extract(member=tarinfo)\n",
        "    for folder in TEST_FOLDER:\n",
        "      if tarinfo.name.startswith(os.path.join(\"lingspam_public\",\"lemm_stop\",folder,\"\")):\n",
        "        test_dir.append(tarinfo.name)\n",
        "        tar.extract(member=tarinfo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Qpd_8pWixts"
      },
      "source": [
        "#1.IG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5Gt6WOsmP8x"
      },
      "source": [
        "def extractWords(msg):\n",
        "  words = re.findall(r'(?<!\\S)[A-Za-z]{2,}(?!\\S)', msg)\n",
        "  for i in range(len(words)):\n",
        "    words[i] = words[i].lower()\n",
        "    words[i] = words[i].replace(\"_\", \"\")\n",
        "    words[i] = re.sub(\"[0-9]+\", \"\", words[i])\n",
        "  words = set(words)\n",
        "  return words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtTMWGbQqbar"
      },
      "source": [
        "bow = set()\n",
        "spam_count,ham_count = 0,0\n",
        "spam_words,ham_words = defaultdict(int), defaultdict(int)\n",
        "for dir in train_dir:\n",
        "  f = open(dir, \"r\")\n",
        "  words = extractWords(f.read())\n",
        "  if dir.find('spmsg')!=-1:\n",
        "    spam_count += 1\n",
        "    for word in words:\n",
        "      bow.add(word)\n",
        "      spam_words[word]+=1\n",
        "  else:\n",
        "    ham_count+=1\n",
        "    for word in words:\n",
        "      bow.add(word)\n",
        "      ham_words[word]+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OJv42jLKEk5"
      },
      "source": [
        "p_spam = spam_count / ( spam_count + ham_count )\n",
        "H_C = - p_spam * np.log2(p_spam) - (1-p_spam) * np.log2(1-p_spam)\n",
        "\n",
        "h = defaultdict(int)\n",
        "for word in bow:\n",
        "  p_0_spam = (1 - spam_words[word] / spam_count) * (p_spam)\n",
        "  p_1_spam = spam_words[word] / spam_count * p_spam\n",
        "  p_0_legit = (1 - ham_words[word] / ham_count) * (1 - p_spam)\n",
        "  p_1_legit = ham_words[word] / ham_count * (1 - p_spam)\n",
        "\n",
        "  p_x = (spam_words[word] + ham_words[word]) / (spam_count + ham_count)\n",
        "  if p_0_spam != 0:\n",
        "    h[word] += p_0_spam * np.log2(p_0_spam / (1 - p_x))\n",
        "  if p_1_spam != 0:\n",
        "    h[word] += p_1_spam * np.log2(p_1_spam / p_x)\n",
        "  if p_0_legit != 0:\n",
        "    h[word] += p_0_legit * np.log2(p_0_legit / (1 - p_x))\n",
        "  if p_1_legit != 0:\n",
        "    h[word] += p_1_legit * np.log2(p_1_legit / p_x)\n",
        "  h[word] = -h[word]\n",
        "\n",
        "i_g = defaultdict(int)\n",
        "for word in bow:\n",
        "  i_g[word] = H_C - h[word]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBidS8sSi2K3"
      },
      "source": [
        "#2.Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Noo-wdrcYoJd"
      },
      "source": [
        "def topN(n):\n",
        " top_n = sorted(i_g.items(), key=lambda kv:kv[1], reverse=True)[:n]\n",
        " return top_n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzPpPo2cmcux"
      },
      "source": [
        "def topNfeatureLabel(n, dirs):\n",
        "  features = {}\n",
        "  for i, pair in enumerate(topN(n)):\n",
        "    features[pair[0]] = i;\n",
        "  data,label = [],[]\n",
        "  for dir in dirs:\n",
        "    temp = [0]*n\n",
        "    f = open(dir, \"r\")\n",
        "    words = extractWords(f.read())\n",
        "    if dir.find('spmsg')!=-1:\n",
        "      label.append(1)\n",
        "    else:\n",
        "      label.append(0)\n",
        "    for word in words:\n",
        "      if word in features:\n",
        "        temp[features[word]] = 1\n",
        "    data.append(temp)\n",
        "  return data,label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruQDKifFcpVV",
        "outputId": "eaed47dc-eec5-4d4d-a851-78651f6e566a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "top_10 = topN(10)\n",
        "top_10_words = []\n",
        "for pair in top_10:\n",
        "  top_10_words.append(pair[0])\n",
        "\n",
        "print(top_10_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['language', 'remove', 'free', 'linguistic', 'university', 'money', 'click', 'market', 'our', 'business']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfh18i8P_qYQ",
        "outputId": "3a6503ec-21a3-4591-e5de-491d40a843c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "f10_train_data, f10_train_label = topNfeatureLabel(10, train_dir)\n",
        "f10_train_data = np.array(f10_train_data)\n",
        "f10_train_label = np.array(f10_train_label)\n",
        "\n",
        "clf10 = BernoulliNB()\n",
        "clf10.fit(f10_train_data, f10_train_label)\n",
        "\n",
        "f10_test_data, f10_test_label = topNfeatureLabel(10, test_dir)\n",
        "f10_test_data = np.array(f10_test_data)\n",
        "f10_test_label = np.array(f10_test_label)\n",
        "pred = clf10.predict(f10_test_data)\n",
        "\n",
        "# spam precision\n",
        "true_spam = 0\n",
        "pred_spam = 0\n",
        "n = len(pred)\n",
        "for i in range(n):\n",
        "  if pred[i] == 1:\n",
        "    pred_spam += 1\n",
        "    if f10_test_label[i] == 1:\n",
        "      true_spam += 1\n",
        "print('{} true spams out of {} predicted spams. spam precision is {:2.2f}. '.format(true_spam, pred_spam, true_spam / pred_spam))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40 true spams out of 45 predicted spams. spam precision is 0.89. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gefw1xvDG0o",
        "outputId": "3594ec51-d667-4578-c250-5f93b02dd90f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# spam recall\n",
        "true_spam = 0\n",
        "spam = 0\n",
        "for i in range(n):\n",
        "  if f10_test_label[i] == 1:\n",
        "    spam += 1\n",
        "    if pred[i] == 1:\n",
        "      true_spam += 1\n",
        "print('{} predicted true spams out of {} all spams. spam recall is {:2.2f}. '.format(true_spam, spam, true_spam / spam))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40 predicted true spams out of 49 all spams. spam recall is 0.82. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_yPn_3CDMp1",
        "outputId": "05a08ca0-1a77-48db-9ad8-a644a8b2c979",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# correct rate\n",
        "correct = 0\n",
        "for i in range(n):\n",
        "  if pred[i] == f10_test_label[i]:\n",
        "    correct += 1\n",
        "print('prediction match rate is {:2.2f}. '.format(correct / n))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prediction match rate is 0.95. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXTuFHIioa1G"
      },
      "source": [
        "| Classifier  | #Features  |  Sapm Precision |  Spam recall | \n",
        "|---|---|---|---|\n",
        "|Bernoulli NB classifier with binary features|10  |0.89|0.82|\n",
        "|Multinomial NB with binary features|10  |   |   |\n",
        "|Multinomial NB with term frequency (TF) features|10  |   |   |\n",
        "|---|---|---|---|\n",
        "|Bernoulli NB classifier with binary features|100 |   |   |\n",
        "|Multinomial NB with binary features|100 |   |   |\n",
        "|Multinomial NB with term frequency (TF) features|100 |   |   |\n",
        "|---|---|---|---|\n",
        "|Bernoulli NB classifier with binary features|1000|   |   |\n",
        "|Multinomial NB with binary features|1000|   |   |\n",
        "|Multinomial NB with term frequency (TF) features|1000|   |   |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoayvGUEiozD"
      },
      "source": [
        "#3.SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNsC-zUNith-"
      },
      "source": [
        "def topNfeatureLabel(n, dirs):\n",
        "  features = {}\n",
        "  for i, pair in enumerate(topN(n)):\n",
        "    features[pair[0]] = i;\n",
        "  data,label = [],[]\n",
        "  for dir in dirs:\n",
        "    temp = [0]*n\n",
        "    f = open(dir, \"r\")\n",
        "    words = extractWords(f.read())\n",
        "    if dir.find('spmsg')!=-1:\n",
        "      label.append(1)\n",
        "    else:\n",
        "      label.append(0)\n",
        "    for word in words:\n",
        "      if word in features:\n",
        "        temp[features[word]] = 1\n",
        "    data.append(temp)\n",
        "  return data,label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wW_UdZpjiQd",
        "outputId": "a5b63605-ce4c-4225-8f4f-d2f00b85099c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X, y = topNfeatureLabel(1000, train_dir)\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "#clf_svm = svm.SVC(C=1000, kernel='linear')\n",
        "clf_svm = svm.SVC(C=1000, kernel='rbf')\n",
        "clf_svm.fit(X_train, y_train)\n",
        "\n",
        "f1000_test_data, f1000_test_label = topNfeatureLabel(1000, test_dir)\n",
        "f1000_test_data = np.array(f1000_test_data)\n",
        "f1000_test_label = np.array(f1000_test_label)\n",
        "pred_svm = clf_svm.predict(f1000_test_data)\n",
        "\n",
        "# spam precision\n",
        "true_spam = 0\n",
        "pred_spam = 0\n",
        "n = len(pred_svm)\n",
        "for i in range(n):\n",
        "  if pred_svm[i] == 1:\n",
        "    pred_spam += 1\n",
        "    if f1000_test_label[i] == 1:\n",
        "      true_spam += 1\n",
        "print('{} true spams out of {} predicted spams. spam precision is {:2.2f}. '.format(true_spam, pred_spam, true_spam / pred_spam))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "46 true spams out of 47 predicted spams. spam precision is 0.98. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "es6H6l7Ymr3v",
        "outputId": "d5694465-6521-4373-b040-89e817e1e860",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# spam recall\n",
        "true_spam = 0\n",
        "spam = 0\n",
        "for i in range(n):\n",
        "  if f1000_test_label[i] == 1:\n",
        "    spam += 1\n",
        "    if pred_svm[i] == 1:\n",
        "      true_spam += 1\n",
        "print('{} predicted true spams out of {} all spams. spam recall is {:2.2f}. '.format(true_spam, spam, true_spam / spam))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "46 predicted true spams out of 49 all spams. spam recall is 0.94. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKPYG5K7nU6Z",
        "outputId": "54e9956b-83fe-444b-e29a-f31ed038309c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('correct prediction rate {:2.2f}. '.format(clf_svm.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "correct prediction rate 0.99. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5qY0Bfpn2lI"
      },
      "source": [
        "#4.Adversarial Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHzpa9mDn-hd"
      },
      "source": [
        "?"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}